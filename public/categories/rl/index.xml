<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RL on &lt;Ashutosh Tiwari/&gt;</title>
    <link>https://ashutoshtiwari13.github.io/categories/rl/</link>
    <description>Recent content in RL on &lt;Ashutosh Tiwari/&gt;</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jul 2020 12:14:34 +0600</lastBuildDate>
    
	<atom:link href="https://ashutoshtiwari13.github.io/categories/rl/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Deep Reinforcement Learning approach to Robot Grasping</title>
      <link>https://ashutoshtiwari13.github.io/publication/paper-5/</link>
      <pubDate>Thu, 30 Jul 2020 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/publication/paper-5/</guid>
      <description>Paper details Under Review in Robotics adn Autonomous Systems (RAS), Elsevier Journals</description>
    </item>
    
    <item>
      <title>Map the Robot World using SLAM and RTAB-MAP</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-4/</link>
      <pubDate>Sat, 23 May 2020 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-4/</guid>
      <description>Project Heads-up SLAM(Simultaneous Localization and mapping) (Nvidia Article here) is a technology where a robot builds a map representing its spatial environment while keeping a track of its position within the built map.</description>
    </item>
    
    <item>
      <title>PR2-Robot 3D Perception and Control</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-3/</link>
      <pubDate>Wed, 15 Apr 2020 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-3/</guid>
      <description>Project Heads-up This project gives the PR2 robot the ability to locate an object in a cluttered environment, pick it up and then move it to some other location.</description>
    </item>
    
    <item>
      <title>Follow me-Quadrocopter Simulation</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-6/</link>
      <pubDate>Fri, 13 Mar 2020 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-6/</guid>
      <description>Project Heads-up A deep neural network to identify and track a target (person) via a simulated Quadrocopter (Simulated using Udacity QuadSim by Unity).</description>
    </item>
    
    <item>
      <title>Training Locomotion using Augmented Random Search</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-8/</link>
      <pubDate>Fri, 20 Dec 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-8/</guid>
      <description>Project Heads-up The project aims on building a new type of Artificial intelligence algorithm which is simple and surpasses many already available algorithms for Humanoid or Mu-Jo-Co(Multidimensionla-Joint-with-contact) locomotion related tasks.</description>
    </item>
    
    <item>
      <title>Ant PyBullet Environment using Soft Actor Critic (SAC)</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-10/</link>
      <pubDate>Sun, 12 May 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-10/</guid>
      <description>Project Heads-up Solving the environment by usage of the Soft Actor Critic algorithm, see the summary of the basic paper here</description>
    </item>
    
    <item>
      <title>Lunar Lander Environment using DDPG</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-14/</link>
      <pubDate>Sun, 12 May 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-14/</guid>
      <description>Project Heads-up Solving the environment require an average total reward of over 200 on 100 consecutive episodes.</description>
    </item>
    
    <item>
      <title>Unity Banana Environment using Deep Q-network (DQN)</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-11/</link>
      <pubDate>Sun, 12 May 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-11/</guid>
      <description>Project Heads-up The agent is trained to navigate (and collect bananas!</description>
    </item>
    
    <item>
      <title>Unity Crawler Environment using Proximal Policy Optimization (PPO)</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-13/</link>
      <pubDate>Sun, 12 May 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-13/</guid>
      <description>Project Heads-up The Crawler environment. A creature with 4 arms and 4 forearms.</description>
    </item>
    
    <item>
      <title>Unity Tennis Environment using Multi-agent DDPG</title>
      <link>https://ashutoshtiwari13.github.io/portfolio/project-15/</link>
      <pubDate>Sun, 12 May 2019 12:14:34 +0600</pubDate>
      
      <guid>https://ashutoshtiwari13.github.io/portfolio/project-15/</guid>
      <description>Project Heads-up The projetc uses the Tennis environment, where two agents control rackets to bounce ball over a net.</description>
    </item>
    
  </channel>
</rss>